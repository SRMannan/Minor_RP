{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRMannan/Minor_RP/blob/main/SPACY_RP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2q4VS4U0hZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef61317-1ef1-43e3-8aaa-13839e84c980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.1/29.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.6.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.2 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.2 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.2 which is incompatible.\n",
            "rmm-cu12 24.6.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -U spacy -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH7WKqop0yGj",
        "outputId": "e97b01ea-6ee3-463c-f35d-eebdb0c9d76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.8.2                         \n",
            "Location         /usr/local/lib/python3.10/dist-packages/spacy\n",
            "Platform         Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "Python version   3.10.12                       \n",
            "Pipelines        en_core_web_sm (3.7.1)        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"hi\") # load a new spacy model\n",
        "db = DocBin() # create a DocBin object"
      ],
      "metadata": {
        "id": "Fu-YNolx0yLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "f = open('/content/combined_annotations234.json')\n",
        "TRAIN_DATA = json.load(f)"
      ],
      "metadata": {
        "id": "D8M6S92I0yOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lFaA-ZQaz-wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('HI')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IaynZq01b-5",
        "outputId": "ac69eb4f-1f12-41f3-a04d-fff77641fdcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, item in enumerate(TRAIN_DATA['annotations']):\n",
        "    if item is None:\n",
        "        print(f\"Item at index {index} is None.\")\n",
        "        continue\n",
        "\n",
        "    # Proceed with processing\n",
        "    text, annot = item\n",
        "    # ... rest of the code ...\n"
      ],
      "metadata": {
        "id": "WjXTQa3Kja1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming TRAIN_DATA is the loaded JSON data\n",
        "cleaned_annotations = [item for item in TRAIN_DATA['annotations'] if item is not None]\n",
        "\n",
        "for text, annot in tqdm(cleaned_annotations):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is not None:\n",
        "            ents.append(span)\n",
        "    # You can continue processing with 'ents' as needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN2Wk-IrjpEl",
        "outputId": "28305d97-6122-40c2-efda-1c7200d48be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1856/1856 [00:00<00:00, 17466.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###for text, annot in tqdm(TRAIN_DATA['annotations']):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    db.add(doc)\n",
        "\n",
        "###db.to_disk(\"./training_data.spacy\") # save the docbin object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "T8a-2F2u1Rqy",
        "outputId": "7f764c82-6cdf-4505-9fa7-460a21bb2e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-7-34438f41105d>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-34438f41105d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    doc = nlp.make_doc(text)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Create a DocBin object to store processed documents\n",
        "db = DocBin()\n",
        "\n",
        "# Filter out any None values from the annotations list\n",
        "cleaned_annotations = [item for item in TRAIN_DATA['annotations'] if item is not None]\n",
        "\n",
        "for text, annot in tqdm(cleaned_annotations):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        # Ensure start and end positions are valid\n",
        "        if start < 0 or end > len(text):\n",
        "            print(f\"Skipping entity with invalid range: {(start, end, label)}\")\n",
        "            continue\n",
        "\n",
        "        # Create a span and check if it's valid\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(f\"Skipping entity: {(start, end, label)}\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "\n",
        "    # Set the entities for the document\n",
        "    doc.ents = ents\n",
        "    # Add the document to the DocBin\n",
        "    db.add(doc)\n",
        "\n",
        "# Save the processed DocBin to disk\n",
        "db.to_disk(\"./training_data.spacy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwDYn5-zj7FR",
        "outputId": "6e83249d-c13e-49a4-e2f9-96159389ff49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 827/1856 [00:00<00:00, 4184.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (24, 29, 'SYMPTOMS')\n",
            "Skipping entity: (7, 16, 'SYMPTOMS')\n",
            "Skipping entity: (7, 16, 'SYMPTOMS')\n",
            "Skipping entity: (7, 13, 'SYMPTOMS')\n",
            "Skipping entity: (18, 23, 'SYMPTOMS')\n",
            "Skipping entity: (7, 13, 'SYMPTOMS')\n",
            "Skipping entity: (18, 23, 'SYMPTOMS')\n",
            "Skipping entity: (7, 14, 'SYMPTOMS')\n",
            "Skipping entity: (7, 14, 'SYMPTOMS')\n",
            "Skipping entity: (7, 16, 'SYMPTOMS')\n",
            "Skipping entity: (7, 15, 'SYMPTOMS')\n",
            "Skipping entity: (7, 13, 'SYMPTOMS')\n",
            "Skipping entity: (18, 23, 'SYMPTOMS')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1856/1856 [00:00<00:00, 4665.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init config config.cfg --lang hi --pipeline ner --optimize efficiency --force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOIomCTx1R4n",
        "outputId": "a937dbea-ca91-4be9-fad9-80d2a95bce5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: hi\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./training_data.spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqElOdK41R7L",
        "outputId": "d7d02cb4-669e-4ea4-d406-9706246d8a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     52.91    0.00    0.00    0.00    0.00\n",
            "  1     200        184.26   3243.27   54.61   59.44   50.51    0.55\n",
            "  2     400        288.77   1694.00   76.10   75.87   76.33    0.76\n",
            "  4     600        336.54   1362.43   87.07   89.08   85.15    0.87\n",
            "  6     800        335.58   1285.24   87.86   88.36   87.36    0.88\n",
            "  8    1000        374.24   1239.74   90.62   90.78   90.46    0.91\n",
            " 12    1200        312.32   1273.54   91.43   91.92   90.94    0.91\n",
            " 15    1400        279.37   1306.05   91.56   91.29   91.83    0.92\n",
            " 20    1600        311.99   1492.46   92.77   92.99   92.55    0.93\n",
            " 26    1800        292.80   1610.05   92.52   92.85   92.19    0.93\n",
            " 33    2000        343.88   1841.60   93.19   93.41   92.96    0.93\n",
            " 42    2200        453.56   2165.80   94.05   93.78   94.34    0.94\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_ner = spacy.load(\"/content/model-best\")"
      ],
      "metadata": {
        "id": "kz3uKBCL46uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-nlp-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn9o806BlGSb",
        "outputId": "c71ad83f-4a87-4f88-b3a5-31f8e55ae013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n",
            "  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n",
            "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.8.30)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: morfessor, docutils, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 5.0.2\n",
            "    Uninstalling Sphinx-5.0.2:\n",
            "      Successfully uninstalled Sphinx-5.0.2\n",
            "Successfully installed docutils-0.21.2 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-8.1.3 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.1 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "\n",
        "# Custom stopwords for Hindi (expand based on your requirements)\n",
        "STOPWORDS  = {\n",
        "    \"अंदर\", \"अत\", \"अदि\", \"अप\", \"अपना\", \"अपनि\", \"अपनी\", \"अपने\", \"अभि\", \"अभी\",\n",
        "    \"आदि\", \"आप\", \"इंहिं\", \"इंहें\", \"इंहों\", \"इतयादि\", \"इत्यादि\", \"इन\", \"इनका\",\n",
        "    \"इन्हीं\", \"इन्हें\", \"इन्हों\", \"इस\", \"इसका\", \"इसकि\", \"इसकी\", \"इसके\", \"इसमें\",\n",
        "    \"इसि\", \"इसी\", \"इसे\", \"उंहिं\", \"उंहें\", \"उंहों\", \"उन\", \"उनका\", \"उनकि\", \"उनकी\",\n",
        "    \"उनके\", \"उनको\", \"उन्हीं\", \"उन्हें\", \"उन्हों\", \"उस\", \"उसके\", \"उसि\", \"उसी\",\n",
        "    \"उसे\", \"एक\", \"एवं\", \"एस\", \"एसे\", \"ऐसे\", \"ओर\", \"और\", \"कइ\", \"कई\", \"कर\", \"करता\",\n",
        "    \"करते\", \"करना\", \"करने\", \"करें\", \"कहते\", \"कहा\", \"का\", \"काफि\", \"काफ़ी\", \"कि\",\n",
        "    \"किंहें\", \"किंहों\", \"कितना\", \"किन्हें\", \"किन्हों\", \"किया\", \"किर\", \"किस\",\n",
        "    \"किसि\", \"किसी\", \"किसे\", \"की\", \"कुछ\", \"कुल\", \"के\", \"को\", \"कोइ\", \"कोई\", \"कोन\",\n",
        "    \"कोनसा\", \"कौन\", \"कौनसा\", \"गया\", \"घर\", \"जब\", \"जहाँ\", \"जहां\", \"जा\", \"जिंहें\",\n",
        "    \"जिंहों\", \"जितना\", \"जिधर\", \"जिन\", \"जिन्हें\", \"जिन्हों\", \"जिस\", \"जिसे\", \"जीधर\",\n",
        "    \"जेसा\", \"जेसे\", \"जैसा\", \"जैसे\", \"जो\", \"तक\", \"तब\", \"तरह\", \"तिंहें\", \"तिंहों\",\n",
        "    \"तिन\", \"तिन्हें\", \"तिन्हों\", \"तिस\", \"तिसे\", \"तो\", \"था\", \"थि\", \"थी\", \"थे\",\n",
        "    \"दबारा\", \"दवारा\", \"दिया\", \"दुसरा\", \"दुसरे\", \"दूसरे\", \"दो\", \"द्वारा\", \"न\",\n",
        "    \"नहिं\", \"नहीं\", \"ना\", \"निचे\", \"निहायत\", \"नीचे\", \"ने\", \"पर\", \"पहले\", \"पुरा\",\n",
        "    \"पूरा\", \"पे\", \"फिर\", \"बनि\", \"बनी\", \"बहि\", \"बही\", \"बहुत\", \"बाद\", \"बाला\",\n",
        "    \"बिलकुल\", \"भि\", \"भितर\", \"भी\", \"भीतर\", \"मगर\", \"मानो\", \"मे\", \"में\", \"यदि\", \"यह\",\n",
        "    \"यहाँ\", \"यहां\", \"यहि\", \"यही\", \"या\", \"यिह\", \"ये\", \"रखें\", \"रवासा\", \"रहा\",\n",
        "    \"रहे\", \"ऱ्वासा\", \"लिए\", \"लिये\", \"लेकिन\", \"व\", \"वगेरह\", \"वरग\", \"वर्ग\", \"वह\",\n",
        "    \"वहाँ\", \"वहां\", \"वहिं\", \"वहीं\", \"वाले\", \"वुह\", \"वे\", \"वग़ैरह\", \"संग\", \"सकता\",\n",
        "    \"सकते\", \"सबसे\", \"सभि\", \"सभी\", \"साथ\", \"साबुत\", \"साभ\", \"सारा\", \"से\", \"सो\",\n",
        "    \"हि\", \"ही\", \"हुअ\", \"हुआ\", \"हुइ\", \"हुई\", \"हुए\", \"हे\", \"हें\", \"है\", \"हैं\",\n",
        "    \"हो\", \"होता\", \"होति\", \"होती\", \"होते\", \"होना\", \"होने\"\n",
        "}\n",
        "\n",
        "# Initialize the Hindi normalizer\n",
        "normalizer_factory = IndicNormalizerFactory()\n",
        "normalizer = normalizer_factory.get_normalizer(\"hi\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Normalize the text\n",
        "    normalized_text = normalizer.normalize(text)\n",
        "\n",
        "    # Tokenize the text using indicnlp\n",
        "    tokens = indic_tokenize.trivial_tokenize(normalized_text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [token for token in tokens if token not in STOPWORDS]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def process_single_conversation(conversation):\n",
        "    conversation = conversation.strip()  # Remove leading and trailing whitespace\n",
        "    if conversation:  # If the conversation is not empty\n",
        "        try:\n",
        "            speaker, text = conversation.split(\":\", 1)  # Split only on the first occurrence\n",
        "            speaker = speaker.strip()\n",
        "            text = text.strip()\n",
        "\n",
        "            # Preprocess the text\n",
        "            tokens = preprocess_text(text)\n",
        "\n",
        "            # Return the processed conversation\n",
        "            return f\"{speaker}: {' '.join(tokens)}\"\n",
        "        except ValueError:\n",
        "            # If the conversation doesn't follow the expected \"Speaker: Text\" format, return None\n",
        "            return None\n",
        "\n",
        "# Example usage for a single input\n",
        "single_conversation = '''मरीज: नमस्ते डॉक्टर, मुझे पिछले कुछ दिनों से तेज बुखार हो रहा है।\n",
        "डॉक्टर: क्या आपको इसके साथ सिरदर्द या बदन दर्द भी हो रहा है?\n",
        "मरीज: हां, मेरे सिर में भी तेज दर्द है और बदन में भारीपन महसूस हो रहा है।\n",
        "डॉक्टर: लगता है आपको वायरल फीवर हो गया है।\n",
        "मरीज: क्या मुझे कोई टेस्ट करवाना पड़ेगा?\n",
        "डॉक्टर: अभी नहीं, लेकिन अगर बुखार तीन दिन में ठीक नहीं होता है, तो आपको ब्लड टेस्ट करवाना पड़ेगा।\n",
        "मरीज: ठीक है। मुझे कौन-कौन सी दवाइयाँ लेनी होंगी?\n",
        "डॉक्टर: मैं आपको पेरासिटामोल और कुछ एंटीबायोटिक दवाइयाँ लिखता हूँ। पेरासिटामोल दिन में तीन बार लीजिए।\n",
        "मरीज: और मुझे कितने दिनों तक आराम करना होगा?\n",
        "डॉक्टर: कम से कम 3-4 दिन पूरी तरह आराम करें। साथ ही खूब पानी पिएं और हल्का खाना खाएं।\n",
        "मरीज: ठीक है डॉक्टर, धन्यवाद।\n",
        "डॉक्टर: ध्यान रखें, और अगर कोई और समस्या हो, तो तुरंत आकर दिखाइए।.\n",
        "'''\n",
        "processed_output = process_single_conversation(single_conversation)\n",
        "\n",
        "if processed_output:\n",
        "    print(f\"Processed Output: {processed_output}\")\n",
        "else:\n",
        "    print(\"The input format is incorrect.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktlP0NjDkwow",
        "outputId": "a18cf1d3-8e30-46a4-b7b2-3351c87b9fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Output: मरीज: नमस्ते डॉक्टर , मुझे पिछले दिनों तेज बुखार । \n",
            "डॉक्टरः क्या आपको सिरदर्द बदन दर्द ? \n",
            "मरीजः हां , मेरे सिर तेज दर्द बदन भारीपन महसूस । \n",
            "डॉक्टरः लगता आपको वायरल फीवर । \n",
            "मरीजः क्या मुझे टेस्ट करवाना पड़ेगा ? \n",
            "डॉक्टरः , अगर बुखार तीन दिन ठीक , आपको ब्लड टेस्ट करवाना पड़ेगा । \n",
            "मरीजः ठीक । मुझे - सी दवाइयाँ लेनी होंगी ? \n",
            "डॉक्टरः मैं आपको पेरासिटामोल एंटीबायोटिक दवाइयाँ लिखता हूँ । पेरासिटामोल दिन तीन बार लीजिए । \n",
            "मरीजः मुझे कितने दिनों आराम होगा ? \n",
            "डॉक्टरः कम कम 3 - 4 दिन पूरी आराम । खूब पानी पिएं हल्का खाना खाएं । \n",
            "मरीजः ठीक डॉक्टर , धन्यवाद । \n",
            "डॉक्टरः ध्यान , अगर समस्या , तुरंत आकर दिखाइए । .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_ner(processed_output)"
      ],
      "metadata": {
        "id": "zkb2lqL95V5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "e-MUrl_J6Yd6",
        "outputId": "65be4ddf-9401-44fe-c896-0a63384e78e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">मरीज: नमस्ते डॉक्टर \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    , मुझे\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SYMPTOMS</span>\n",
              "</mark>\n",
              " पिछले दिनों तेज \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    बुखार\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SYMPTOMS</span>\n",
              "</mark>\n",
              " । <br>डॉक्टरः क्या आपको \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    सिरदर्द\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SYMPTOMS</span>\n",
              "</mark>\n",
              " बदन दर्द ? <br>मरीजः हां , मेरे \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    सिर तेज दर्द बदन भारीपन\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SYMPTOMS</span>\n",
              "</mark>\n",
              " महसूस । <br>डॉक्टरः लगता आपको \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    वायरल फीवर\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DIAGNOSIS</span>\n",
              "</mark>\n",
              " । <br>मरीजः क्या मुझे टेस्ट करवाना पड़ेगा ? <br>डॉक्टरः , अगर बुखार तीन दिन ठीक , आपको \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ब्लड टेस्ट\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TESTS</span>\n",
              "</mark>\n",
              " करवाना पड़ेगा । <br>मरीजः ठीक । मुझे - सी दवाइयाँ लेनी होंगी ? <br>डॉक्टरः मैं आपको \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    पेरासिटामोल\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICINES</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    एंटीबायोटिक\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICINES</span>\n",
              "</mark>\n",
              " दवाइयाँ लिखता हूँ । पेरासिटामोल दिन तीन बार लीजिए । <br>मरीजः मुझे कितने दिनों आराम होगा ? <br>डॉक्टरः कम कम 3 - 4 दिन पूरी \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    आराम\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADVICE</span>\n",
              "</mark>\n",
              " । \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    खूब पानी पिएं हल्का खाना खाएं\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADVICE</span>\n",
              "</mark>\n",
              " । <br>मरीजः ठीक डॉक्टर , धन्यवाद । <br>डॉक्टरः ध्यान , अगर समस्या , तुरंत आकर दिखाइए । .</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***UPTILL HERE ONLY***"
      ],
      "metadata": {
        "id": "crnb3NBxzfVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import json\n",
        "\n",
        "# Example text (replace with your actual text)\n",
        "text = '''Patient: Doctor, I’ve been experiencing sharp pain in my shoulder and upper arm.\n",
        "Doctor: When did the pain start, and have you had any recent injuries or activities that might have caused it?\n",
        "Patient: The pain started about a week ago, and I haven’t had any recent injuries. I do a lot of typing at work.\n",
        "Doctor: This could be due to a rotator cuff issue or a repetitive strain injury. I recommend an MRI of the shoulder and a physical therapy evaluation.\n",
        "Patient: I’ll get those arranged. Should I avoid any activities in the meantime?\n",
        "Doctor: Yes, try to limit activities that strain your shoulder and apply ice to reduce inflammation. Follow up after the tests to discuss treatment options.\n",
        "Patient: Thank you.'''\n",
        "\n",
        "# Load your trained model (replace with your actual model path)\n",
        "nlp_ner = spacy.load(\"/content/model-best\")\n",
        "\n",
        "# Process the text\n",
        "doc = nlp_ner(text)\n",
        "\n",
        "# Initialize a dictionary to hold the unique entities for each label\n",
        "label_entities = {}\n",
        "\n",
        "# Process the entities\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ not in label_entities:\n",
        "        label_entities[ent.label_] = set()\n",
        "    label_entities[ent.label_].add(ent.text)\n",
        "\n",
        "# Convert sets to lists for JSON serialization\n",
        "label_entities = {label: list(entities) for label, entities in label_entities.items()}\n",
        "\n",
        "# Structure the data\n",
        "doc_data = {\n",
        "    \"text\": doc.text,\n",
        "    \"entities\": label_entities\n",
        "}\n",
        "\n",
        "# Save the data to a JSON file\n",
        "json_output_path = '/content/doc_data.json'\n",
        "with open(json_output_path, 'w') as json_file:\n",
        "    json.dump(doc_data, json_file, indent=4)\n",
        "\n",
        "print(f\"Data saved to {json_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXsOmEtlANz1",
        "outputId": "feb6d3c5-cd73-48ac-b16f-47223adb20ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/doc_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model_best.zip /content/model-best\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac-keLxeLJ9T",
        "outputId": "bfe7c41e-a0d8-4b0d-ebed-8d6792827561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/model-best/ (stored 0%)\n",
            "  adding: content/model-best/config.cfg (deflated 61%)\n",
            "  adding: content/model-best/tok2vec/ (stored 0%)\n",
            "  adding: content/model-best/tok2vec/cfg (stored 0%)\n",
            "  adding: content/model-best/tok2vec/model (deflated 8%)\n",
            "  adding: content/model-best/vocab/ (stored 0%)\n",
            "  adding: content/model-best/vocab/vectors (deflated 45%)\n",
            "  adding: content/model-best/vocab/strings.json (deflated 72%)\n",
            "  adding: content/model-best/vocab/key2row (stored 0%)\n",
            "  adding: content/model-best/vocab/vectors.cfg (stored 0%)\n",
            "  adding: content/model-best/vocab/lookups.bin (stored 0%)\n",
            "  adding: content/model-best/meta.json (deflated 67%)\n",
            "  adding: content/model-best/ner/ (stored 0%)\n",
            "  adding: content/model-best/ner/cfg (deflated 33%)\n",
            "  adding: content/model-best/ner/model (deflated 8%)\n",
            "  adding: content/model-best/ner/moves (deflated 66%)\n",
            "  adding: content/model-best/tokenizer (deflated 81%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model_best.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "j-LcvpoYLdBQ",
        "outputId": "49626e39-95e3-4580-f5b6-565787fe9d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b9458bde-a593-4476-8276-111d9d9dfe06\", \"model_best.zip\", 5662416)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}